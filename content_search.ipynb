{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set date range for weekly report\n",
    "date_range_high = datetime.today().date()\n",
    "date_range_low = datetime.today().date() - timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'Mozilla/5.0 (iPad; U; CPU OS 3_2_1 like Mac OS X; en-us) AppleWebKit/531.21.10 (KHTML, like Gecko) Mobile/7B405'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reuters M&A News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### webscrape Reuters M&A News\n",
    "\n",
    "date_filter = date_range_high\n",
    "page_number = 1\n",
    "reuters_news_dict = {}\n",
    "reuters_news_url = \"https://www.reuters.com/news/archive/mergersnews?view=page&page={}&pageSize=10\"\n",
    "\n",
    "while date_filter >= date_range_low:\n",
    "\n",
    "    reuters_raw = requests.get(reuters_news_url.format(page_number), headers={'User-Agent': user_agent})\n",
    "    reuters_bs4 = BeautifulSoup(reuters_raw.content)\n",
    "\n",
    "    reuters_news_block = reuters_bs4.find_all('div', class_ = 'column1 col col-10')\n",
    "    reuters_news_list  = reuters_news_block[0].find_all('h3', class_ = 'story-title')\n",
    "    reuters_timestamp_list = reuters_news_block[0].find_all('span', class_ = 'timestamp')\n",
    "\n",
    "    for i in range(len(reuters_news_list)):\n",
    "        title = reuters_news_list[i].get_text()\n",
    "        title = title.split('\\n\\t\\t\\t\\t\\t\\t\\t\\t')[1]\n",
    "\n",
    "        a_date = reuters_timestamp_list[i].get_text()\n",
    "        if 'am' in a_date or 'pm' in a_date:\n",
    "            a_date = datetime.today().date()\n",
    "        else:\n",
    "            a_date = datetime.strptime(a_date, \"%b %d %Y\").date()\n",
    "\n",
    "        reuters_news_dict[title] = a_date\n",
    "\n",
    "    date_filter = a_date\n",
    "    page_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_news_dict = {title: date for title, date in reuters_news_dict.items() if date >= date_range_low}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reuters_news_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuters_news_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeking Alpha M&A News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### webscrape Seeking Alpha M&A News\n",
    "\n",
    "options = Options()\n",
    "# options.add_argument(\"start-maximized\")\n",
    "# options.add_argument('--headless')\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "s = Service('/Users/babyghost/.wdm/drivers/chromedriver/mac64/97.0.4692.71/chromedriver')\n",
    "driver = webdriver.Chrome(service= s, options=options); \n",
    "\n",
    "# driver = webdriver.Chrome(service = ChromeDriverManager().install(), options = options) ### figure out your chromedriver path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m formatted_date_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://seekingalpha.com/market-news/m-a?page=1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m article_block \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//*[@id=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]/div/div[2]/div/div[2]/section/div/div/div/div[2]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(article_block):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "article_list = []\n",
    "formatted_date_list = []\n",
    "\n",
    "driver.get('https://seekingalpha.com/market-news/m-a?page=1')\n",
    "\n",
    "article_block = driver.find_elements(By.XPATH, \"//*[@id='content']/div/div[2]/div/div[2]/section/div/div/div/div[2]\")[0].text.split('\\n')\n",
    "\n",
    "for i, j in enumerate(article_block):\n",
    "    if i%2 == 0:\n",
    "        article_list.append(j)\n",
    "\n",
    "date_list = driver.find_elements(By.XPATH, \"//*[@id='content']/div/div[3]/div/div[2]/section/div/div/div/div[2]/article[1]/div/div/footer/span[2]\")\n",
    "date_list = [i.text for i in date_list] \n",
    "\n",
    "for a_date in date_list:\n",
    "    if 'Today' in a_date:\n",
    "        a_date = datetime.today().date()\n",
    "    elif 'Yesterday' in a_date:\n",
    "        a_date = datetime.today().date() - timedelta(days = 1)\n",
    "    elif len(a_date.split(' ')) == 3:\n",
    "        a_date = a_date + ' ' + str(datetime.today().date().year)\n",
    "        a_date = datetime.strptime(a_date, \"%a, %b. %d %Y\").date()\n",
    "    else:\n",
    "        a_date = datetime.strptime(a_date, \"%a, %b. %d, %Y\").date()\n",
    "    \n",
    "    formatted_date_list.append(a_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeking_alpha_news_dict = dict(zip(article_list, formatted_date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeking_alpha_news_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### theMiddleMarket M&A News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_news_url = 'https://www.themiddlemarket.com/latest-news'\n",
    "driver.get(ma_news_url)\n",
    "\n",
    "latest_news = driver.find_elements(By.XPATH,\"/html/body/main/div/div/div/div[1]/div/div\")\n",
    "latest_news = latest_news[0].text.split('\\n')\n",
    "\n",
    "ma_article_list = [i for count, i in enumerate(latest_news) if count%2 == 0 ] \n",
    "ma_date_list = [i for count, i in enumerate(latest_news) if count%2 != 0 ] \n",
    "theMiddleMarket_news_dict =  dict(zip(ma_article_list, ma_date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "theMiddleMarket_news_dict = {key: datetime.strptime(value.title(), '%B %d, %Y').date() for key, value in theMiddleMarket_news_dict.items()}\n",
    "theMiddleMarket_news_dict = {title: date for title, date in theMiddleMarket_news_dict.items() if date >= date_range_low}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theMiddleMarket_news_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor Twitter Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_doc = pd.read_excel('jh_twitter_api_doc.xlsx')\n",
    "\n",
    "consumer_key = api_doc['key'][0]\n",
    "consumer_secret = api_doc['secret'][0]\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    redirect_url = auth.get_authorization_url()\n",
    "except tweepy.TweepError:\n",
    "    print('Error! Failed to get request token.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.set('request_token', auth.request_token['oauth_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
