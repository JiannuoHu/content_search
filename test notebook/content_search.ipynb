{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set date range for weekly report\n",
    "date_range_high = datetime.today().date()\n",
    "date_range_low = datetime.today().date() - timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'Mozilla/5.0 (iPad; U; CPU OS 3_2_1 like Mac OS X; en-us) AppleWebKit/531.21.10 (KHTML, like Gecko) Mobile/7B405'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reuters M&A News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### webscrape Reuters M&A News\n",
    "date_filter = date_range_high\n",
    "page_number = 1\n",
    "reuters_news_dict = {}\n",
    "reuters_news_url = \"https://www.reuters.com/news/archive/mergersnews?view=page&page={}&pageSize=10\"\n",
    "\n",
    "while date_filter >= date_range_low:\n",
    "\n",
    "    reuters_raw = requests.get(reuters_news_url.format(page_number), headers={'User-Agent': user_agent})\n",
    "    reuters_bs4 = BeautifulSoup(reuters_raw.content)\n",
    "\n",
    "    reuters_news_block = reuters_bs4.find_all('div', class_ = 'column1 col col-10')\n",
    "    reuters_news_list  = reuters_news_block[0].find_all('h3', class_ = 'story-title')\n",
    "    reuters_timestamp_list = reuters_news_block[0].find_all('span', class_ = 'timestamp')\n",
    "\n",
    "    for i in range(len(reuters_news_list)):\n",
    "        title = reuters_news_list[i].get_text()\n",
    "        title = title.split('\\n\\t\\t\\t\\t\\t\\t\\t\\t')[1]\n",
    "\n",
    "        a_date = reuters_timestamp_list[i].get_text()\n",
    "        if 'am' in a_date or 'pm' in a_date:\n",
    "            a_date = datetime.today().date()\n",
    "        else:\n",
    "            a_date = datetime.strptime(a_date, \"%b %d %Y\").date()\n",
    "\n",
    "        reuters_news_dict[title] = a_date\n",
    "\n",
    "    date_filter = a_date\n",
    "    page_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_news_dict = {title: date for title, date in reuters_news_dict.items() if date >= date_range_low}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WSJ Deals News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj_deals_url = \"https://www.wsj.com/news/types/deals-deal-makers?page={}\"\n",
    "page_number = 1\n",
    "date_filter = date_range_high\n",
    "\n",
    "while date_filter >= date_range_low:\n",
    "    wsj_raw = requests.get(wsj_deals_url.format(page_number), headers={'User-Agent': user_agent})\n",
    "    wsj_bs4 = BeautifulSoup(wsj_raw.content)\n",
    "\n",
    "    title_list = []\n",
    "    for artilce in wsj_bs4.select('h2[class*=\"headline\"]'):\n",
    "        content = artilce.get_text()\n",
    "        title_list.append(content)\n",
    "\n",
    "    date_list = []\n",
    "    for timestamp in wsj_bs4.select('div[class*=\"timestamp\"]'):\n",
    "        a_date = timestamp.get_text()\n",
    "        a_date = datetime.strptime(a_date, \"%B %d, %Y\").date()\n",
    "        date_list.append(a_date)\n",
    "\n",
    "    date_filter = a_date\n",
    "    page_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj_news_dict = dict(zip(title_list, date_list))\n",
    "wsj_news_dict = {title: date for title, date in wsj_news_dict.items() if date >= date_range_low}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj_news_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "s = Service('chromedriver/chromedriver')\n",
    "driver = webdriver.Chrome(service= s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### theMiddleMarket M&A News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_news_url = 'https://www.themiddlemarket.com/latest-news'\n",
    "driver.get(ma_news_url)\n",
    "\n",
    "latest_news = driver.find_elements(By.XPATH,\"/html/body/main/div/div/div/div[1]/div/div\")\n",
    "latest_news = latest_news[0].text.split('\\n')\n",
    "\n",
    "ma_article_list = [i for count, i in enumerate(latest_news) if count%2 == 0 ] \n",
    "ma_date_list = [i for count, i in enumerate(latest_news) if count%2 != 0 ] \n",
    "theMiddleMarket_news_dict =  dict(zip(ma_article_list, ma_date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theMiddleMarket_news_dict = {key: datetime.strptime(value.title(), '%B %d, %Y').date() for key, value in theMiddleMarket_news_dict.items()}\n",
    "theMiddleMarket_news_dict = {title: date for title, date in theMiddleMarket_news_dict.items() if date >= date_range_low}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theMiddleMarket_news_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New York Times Mergers News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_url = \"https://www.nytimes.com/topic/subject/mergers-acquisitions-and-divestitures\"\n",
    "driver.get(nyt_url)\n",
    "nyt_news_raw = driver.find_elements(By.XPATH, '//*[@id=\"collection-Mergers, Acquisitions and Divestitures\"]/div[1]/div')[0].text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "date_list = []\n",
    "for count, text in enumerate(nyt_news_raw):\n",
    "    try:\n",
    "        a_date = datetime.strptime(text, \"%b. %d, %Y\")\n",
    "        date_list.append(a_date)\n",
    "        index_list.append(count -2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "title_list = [nyt_news_raw[i] for i in index_list]\n",
    "nyt_ma_news_dict = dict(zip(title_list, date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dict = {}\n",
    "for i in [nyt_ma_news_dict, theMiddleMarket_news_dict, reuters_news_dict]:\n",
    "    for k,v in i.items():\n",
    "        combined_dict[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elephants = pd.read_excel('elephants.xlsx')\n",
    "elephants_dict = elephants.set_index('Client').to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elephants_dict[\"BNP Paribas\"] = {'Broker': 'xxx', 'Broker Email': 'xxx.xxx@cbre.com'}\n",
    "elephants_dict[\"DemandDrive\"] = {'Broker': 'xxx', 'Broker Email': 'xxx.xxx@cbre.com'}\n",
    "elephants_dict['Intel'] = {'Broker': 'xxx', 'Broker Email': 'xxx.xxx@cbre.com'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for client in elephants_dict.keys():\n",
    "    client_res = []\n",
    "    for title, date in combined_dict.items():\n",
    "        if client.lower() in title.lower():\n",
    "            client_res.append(title)\n",
    "    if client_res:\n",
    "        results[client] = {'news': client_res, 'broker': elephants_dict[client]['Broker'], 'broker_email':elephants_dict[client]['Broker Email']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).T.reset_index().rename(columns = {'index': 'company'})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeking Alpha M&A News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_list = []\n",
    "formatted_date_list = []\n",
    "\n",
    "driver.get('https://seekingalpha.com/market-news/m-a?page=1')\n",
    "\n",
    "article_block = driver.find_elements(By.XPATH, \"//*[@id='content']/div/div[2]/div/div[2]/section/div/div/div/div[2]\")[0].text.split('\\n')\n",
    "\n",
    "for i, j in enumerate(article_block):\n",
    "    if i%2 == 0:\n",
    "        article_list.append(j)\n",
    "\n",
    "date_list = driver.find_elements(By.XPATH, \"//*[@id='content']/div/div[3]/div/div[2]/section/div/div/div/div[2]/article[1]/div/div/footer/span[2]\")\n",
    "date_list = [i.text for i in date_list] \n",
    "\n",
    "for a_date in date_list:\n",
    "    if 'Today' in a_date:\n",
    "        a_date = datetime.today().date()\n",
    "    elif 'Yesterday' in a_date:\n",
    "        a_date = datetime.today().date() - timedelta(days = 1)\n",
    "    elif len(a_date.split(' ')) == 3:\n",
    "        a_date = a_date + ' ' + str(datetime.today().date().year)\n",
    "        a_date = datetime.strptime(a_date, \"%a, %b. %d %Y\").date()\n",
    "    else:\n",
    "        a_date = datetime.strptime(a_date, \"%a, %b. %d, %Y\").date()\n",
    "    \n",
    "    formatted_date_list.append(a_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeking_alpha_news_dict = dict(zip(article_list, formatted_date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeking_alpha_news_dict"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
