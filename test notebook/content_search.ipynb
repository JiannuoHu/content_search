{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from lxml import etree, html\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set date range for weekly report\n",
    "date_range_high = datetime.today().date()\n",
    "date_range_low = datetime.today().date() - timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'Mozilla/5.0 (iPad; U; CPU OS 3_2_1 like Mac OS X; en-us) AppleWebKit/531.21.10 (KHTML, like Gecko) Mobile/7B405'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reuters M&A News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### webscrape Reuters M&A News\n",
    "date_filter = date_range_high\n",
    "page_number = 1\n",
    "reuters_news_dict = {}\n",
    "reuters_news_url = \"https://www.reuters.com/news/archive/mergersnews?view=page&page={}&pageSize=10\"\n",
    "\n",
    "while date_filter >= date_range_low:\n",
    "\n",
    "    reuters_raw = requests.get(reuters_news_url.format(page_number), headers={'User-Agent': user_agent})\n",
    "    reuters_bs4 = BeautifulSoup(reuters_raw.content)\n",
    "\n",
    "    reuters_news_block = reuters_bs4.find_all('div', class_ = 'column1 col col-10')\n",
    "    reuters_news_list  = reuters_news_block[0].find_all('h3', class_ = 'story-title')\n",
    "    reuters_timestamp_list = reuters_news_block[0].find_all('span', class_ = 'timestamp')\n",
    "\n",
    "    for i in range(len(reuters_news_list)):\n",
    "        title = reuters_news_list[i].get_text()\n",
    "        title = title.split('\\n\\t\\t\\t\\t\\t\\t\\t\\t')[1]\n",
    "\n",
    "        a_date = reuters_timestamp_list[i].get_text()\n",
    "        if 'am' in a_date or 'pm' in a_date:\n",
    "            a_date = datetime.today().date()\n",
    "        else:\n",
    "            a_date = datetime.strptime(a_date, \"%b %d %Y\").date()\n",
    "\n",
    "        reuters_news_dict[title] = a_date\n",
    "\n",
    "    date_filter = a_date\n",
    "    page_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_news_dict = {title: date for title, date in reuters_news_dict.items() if date >= date_range_low}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WSJ Deals News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def scrape_wsj_news(event, context):\n",
    "\n",
    "    date_range_high = datetime.today().date()\n",
    "    date_range_low = datetime.today().date() - timedelta(days=7)\n",
    "\n",
    "    user_agent = 'Mozilla/5.0 (iPad; U; CPU OS 3_2_1 like Mac OS X; en-us) AppleWebKit/531.21.10 (KHTML, like Gecko) Mobile/7B405'\n",
    "    wsj_deals_url = \"https://www.wsj.com/news/types/deals-deal-makers?page={}\"\n",
    "    page_number = 1\n",
    "    date_filter = date_range_high\n",
    "\n",
    "    title_list = []\n",
    "    date_list = []\n",
    "\n",
    "    while date_filter >= date_range_low:\n",
    "        wsj_raw = requests.get(wsj_deals_url.format(page_number), headers={'User-Agent': user_agent})\n",
    "        status = True\n",
    "        timer = 0\n",
    "\n",
    "        while status and timer <=9:\n",
    "            if wsj_raw.status_code != 200:\n",
    "                print(\"wsj page {} status code is not 200, entering sleep for 3 seconds\".format(page_number))\n",
    "                time.sleep(3)\n",
    "                timer += 3\n",
    "                wsj_raw = requests.get(wsj_deals_url.format(page_number), headers={'User-Agent': user_agent})\n",
    "            else:\n",
    "                status = False\n",
    "        \n",
    "        if wsj_raw.status_code == 200:\n",
    "\n",
    "            wsj_bs4 = BeautifulSoup(wsj_raw.content, features=\"lxml\")\n",
    "            article_list = wsj_bs4.select('h2[class*=\"headline\"]')\n",
    "            combined_ts = wsj_bs4.select('div[class*=\"timestamp\"]')\n",
    "\n",
    "            if article_list!=[] and combined_ts!=[]:\n",
    "                for article in article_list:\n",
    "                    content = article.get_text()\n",
    "                    title_list.append(content)\n",
    "                    \n",
    "                for timestamp in combined_ts:\n",
    "                    try:\n",
    "                        a_date = timestamp.find('div').get_text()\n",
    "                        a_date = datetime.strptime(a_date, \"%B %d, %Y\").date()\n",
    "                        date_list.append(a_date)\n",
    "                    except:\n",
    "                        pass\n",
    "            else:\n",
    "                a_date = datetime.today().date() - timedelta(days=8)\n",
    "\n",
    "            date_filter = a_date\n",
    "            page_number += 1\n",
    "        \n",
    "        else:\n",
    "            date_filter = datetime.today().date() - timedelta(days=8)\n",
    "\n",
    "    wsj_news_dict = dict(zip(title_list, date_list))\n",
    "    wsj_news_dict = {title: str(date) for title, date in wsj_news_dict.items() if date >= date_range_low}\n",
    "\n",
    "    return wsj_news_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Zendesk Scraps Deal With SurveyMonkey Parent': '2022-02-25',\n",
       " 'Healthcare Realty Trust Nears Deal With Healthcare Trust of America': '2022-02-24',\n",
       " 'Standard General to Buy TV Broadcaster Tegna for $5.4 Billion': '2022-02-22',\n",
       " 'SoFi to Buy Technisys for About $1.1 Billion': '2022-02-22'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_wsj_news(None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New York Times Mergers News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_nyt_news(event, context):\n",
    "    date_range_low = datetime.today().date() - timedelta(days=7)\n",
    "    user_agent = 'Mozilla/5.0 (iPad; U; CPU OS 3_2_1 like Mac OS X; en-us) AppleWebKit/531.21.10 (KHTML, like Gecko) Mobile/7B405'\n",
    "    ma_news_url = \"https://www.nytimes.com/topic/subject/mergers-acquisitions-and-divestitures\"\n",
    "    nyt_raw = requests.get(ma_news_url, headers={'User-Agent': user_agent})\n",
    "\n",
    "    status = True\n",
    "    timer = 0\n",
    "\n",
    "    while status and timer <=9:\n",
    "        if nyt_raw.status_code != 200:\n",
    "            print(\"nyt status code is not 200, entering sleep for 3 seconds\")\n",
    "            time.sleep(3)\n",
    "            timer += 3\n",
    "            nyt_raw = requests.get(ma_news_url, headers={'User-Agent': user_agent})\n",
    "        else:\n",
    "            status = False\n",
    "\n",
    "    title_list = []\n",
    "    date_list = []\n",
    "\n",
    "    if nyt_raw.status_code == 200:\n",
    "        nyt_content = BeautifulSoup(nyt_raw.content)\n",
    "\n",
    "        title_list = nyt_content.find_all('ol')[0].find_all('h2')\n",
    "        link_list = nyt_content.find_all('ol')[0].find_all('a')\n",
    "\n",
    "        if title_list !=[] and link_list !=[]:\n",
    "            try:\n",
    "                title_list = [i.get_text() for i in title_list]\n",
    "                \n",
    "                date_list = []\n",
    "                link_list = [i['href'].split('/')[1:4] for i in link_list]\n",
    "                \n",
    "                for sub in link_list:\n",
    "                    date_elements = [int(i) for i in sub]\n",
    "                    a_date = datetime(year = date_elements[0], month = date_elements[1], day = date_elements[2]).date()\n",
    "                    date_list.append(a_date)\n",
    "            except:\n",
    "                title_list = []\n",
    "                date_list = []\n",
    "        else:\n",
    "            title_list = []\n",
    "            date_list = []\n",
    "\n",
    "    nyt_ma_news_dict = dict(zip(title_list, date_list))\n",
    "    nyt_ma_news_dict = {title: str(date) for title, date in nyt_ma_news_dict.items() if date >= date_range_low}\n",
    "\n",
    "    return nyt_ma_news_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Uber distances itself from Yandex.Taxi, the Russian ride-sharing service.': '2022-02-28',\n",
       " 'Neil Diamond Sells Entire Catalog to Universal Music': '2022-02-28',\n",
       " 'Chris Licht, a Creator of ‘Morning Joe’ and ‘Colbert’ Producer, Is Set to Run CNN': '2022-02-26',\n",
       " 'Justice Dept. Sues to Block $13 Billion Deal by UnitedHealth Group': '2022-02-24',\n",
       " 'Met Buys Italian Renaissance Bronze After Two Decades on the Hunt': '2022-02-23',\n",
       " 'Volkswagen is considering a plan to spin off Porsche in a public offering.': '2022-02-22'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_nyt_news(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "s = Service('chromedriver/chromedriver')\n",
    "driver = webdriver.Chrome(service= s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### theMiddleMarket M&A News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_news_url = 'https://www.themiddlemarket.com/latest-news'\n",
    "driver.get(ma_news_url)\n",
    "\n",
    "latest_news = driver.find_elements(By.XPATH,\"/html/body/main/div/div/div/div[1]/div/div\")\n",
    "latest_news = latest_news[0].text.split('\\n')\n",
    "\n",
    "ma_article_list = [i for count, i in enumerate(latest_news) if count%2 == 0 ] \n",
    "ma_date_list = [i for count, i in enumerate(latest_news) if count%2 != 0 ] \n",
    "theMiddleMarket_news_dict =  dict(zip(ma_article_list, ma_date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theMiddleMarket_news_dict = {key: datetime.strptime(value.title(), '%B %d, %Y').date() for key, value in theMiddleMarket_news_dict.items()}\n",
    "theMiddleMarket_news_dict = {title: date for title, date in theMiddleMarket_news_dict.items() if date >= date_range_low}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theMiddleMarket_news_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New York Times Mergers News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_url = \"https://www.nytimes.com/topic/subject/mergers-acquisitions-and-divestitures\"\n",
    "driver.get(nyt_url)\n",
    "nyt_news_raw = driver.find_elements(By.XPATH, '//*[@id=\"collection-Mergers, Acquisitions and Divestitures\"]/div[1]/div')[0].text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "date_list = []\n",
    "for count, text in enumerate(nyt_news_raw):\n",
    "    try:\n",
    "        a_date = datetime.strptime(text, \"%b. %d, %Y\")\n",
    "        date_list.append(a_date)\n",
    "        index_list.append(count -2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "title_list = [nyt_news_raw[i] for i in index_list]\n",
    "nyt_ma_news_dict = dict(zip(title_list, date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dict = {}\n",
    "for i in [nyt_ma_news_dict, theMiddleMarket_news_dict, reuters_news_dict]:\n",
    "    for k,v in i.items():\n",
    "        combined_dict[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeking Alpha M&A News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_list = []\n",
    "formatted_date_list = []\n",
    "\n",
    "driver.get('https://seekingalpha.com/market-news/m-a?page=1')\n",
    "\n",
    "article_block = driver.find_elements(By.XPATH, \"//*[@id='content']/div/div[2]/div/div[2]/section/div/div/div/div[2]\")[0].text.split('\\n')\n",
    "\n",
    "for i, j in enumerate(article_block):\n",
    "    if i%2 == 0:\n",
    "        article_list.append(j)\n",
    "\n",
    "date_list = driver.find_elements(By.XPATH, \"//*[@id='content']/div/div[3]/div/div[2]/section/div/div/div/div[2]/article[1]/div/div/footer/span[2]\")\n",
    "date_list = [i.text for i in date_list] \n",
    "\n",
    "for a_date in date_list:\n",
    "    if 'Today' in a_date:\n",
    "        a_date = datetime.today().date()\n",
    "    elif 'Yesterday' in a_date:\n",
    "        a_date = datetime.today().date() - timedelta(days = 1)\n",
    "    elif len(a_date.split(' ')) == 3:\n",
    "        a_date = a_date + ' ' + str(datetime.today().date().year)\n",
    "        a_date = datetime.strptime(a_date, \"%a, %b. %d %Y\").date()\n",
    "    else:\n",
    "        a_date = datetime.strptime(a_date, \"%a, %b. %d, %Y\").date()\n",
    "    \n",
    "    formatted_date_list.append(a_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeking_alpha_news_dict = dict(zip(article_list, formatted_date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeking_alpha_news_dict"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
